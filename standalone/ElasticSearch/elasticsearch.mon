#!/bin/bash

rpath=$(readlink -f "$BASH_SOURCE")
rcommand=${rpath##*/}
rpath=${rpath%/*}
#*/
[ -z "$M_ROOT" ] && M_ROOT=$(readlink -f "$rpath/../../")

DIFF=`which diff 2>/dev/null`
[ -z "$DIFF" ] && echo "Diff utility not found, exiting..  " && exit 1
CURL=`which curl 2>/dev/null`
[ -z "$CURL" ] && echo "Curl not found, exiting..  " && exit 1
CURL="$CURL -s"
source "$M_ROOT/conf/mon.conf" || exit 1
source "$rpath/${rcommand%.mon}.conf"
SQLITE=dbquery
MAILX=`which mail 2>/dev/null`
M_TEMP="$M_TEMP/elasticsearch"
LOG="$M_ROOT/logs/sa.log"
source "$M_ROOT/lib/functions.sh"
source "$M_ROOT/lib/cloud_functions.sh"

timeindexnow=`date +"%s"`
debug=false

get_lock

function print_servers() {
  for host in $@ ; do
    echo "$host"
  done
}

function collect_hosts() {
  for name in $@ ; do
    port=`echo "$name" | cut -sd':' -f2`
    rname=`find_name "${name%%:*}"`
    [ -z "$rname" ] && rname="${name%%:*}"
    [ -n "$port" ] || port=$defaultport
    configips="$configips ${rname}:$port"
  done
}

if [ -n "$ES_SERVERS" ] ; then
  defaultport=9200
  ES_SERVERS=`echo $ES_SERVERS | sed 's|,| |g'`
  for name in $ES_SERVERS ; do
    if [ `grep -c ^$name\| "$M_ROOT/conf/clusters.conf"` -eq 0 ] ; then
      noncluster=1
    else
      cluster=1
    fi
    # In case some server has the same name as cluster
    if [ `grep -c "|$name|$name" "$M_ROOT/servers.list"` -gt 0 ] ; then
      unset cluster
    fi
  done
  
  [ "_$cluster" == "_1" ] && [ "_$noncluster" == "_1" ] && echo "Wrong cluster name in ES_SERVERS or both cluster and server names are present which is not supported" && unlock_exit 1
  
  if [ "_$noncluster" == "_1" ] ; then
  # ES_SERVERS contains hosts
    for server in $ES_SERVERS ; do
      host=`echo "$server" | cut -d':' -f1`
      port=`echo "$server" | cut -sd':' -f2`
      clustername=`cat "$M_ROOT/servers.list" | grep -E "\|$host\||^$host\|" | cut -d'|' -f5`
      [ -z "$clustername" ] && log "Cluster name for server $server not found, check your settings!" && continue
      [ "_$clustername" == "_$clusternameprev" ] && continue
      
      clusterips=`"$M_ROOT/cloud/common/get_ips" --cluster="$clustername" | sed "s|$|:$port|"`
      
      clusternameprev=$clustername
      clusternames="$clusternames $clustername"
      collect_hosts $clusterips
      eval "${clustername}ips=\"$configips\""
    done
  else
  # ES_SERVERS contains clusters
    for name in $ES_SERVERS ; do
      clustername=`echo "$name" | cut -d':' -f1`
      [ -z "$clustername" ] && log "Cluster name $name not found, check your settings!" && continue
      port=`echo "$name" | cut -sd':' -f2`
      clusterips=`"$M_ROOT/cloud/common/get_ips" --cluster="$clustername" | sed "s|$|:$port|"`
      collect_hosts $clusterips
      eval "${clustername}ips=\"$configips\""
      unset clusterips configips
      clusternames="$clusternames $clustername"
    done
  fi
else
  log "ES_SERVERS variable is not defined, check ${rcommand}.conf"
  unlock_exit 1
fi
$debug && log "hosts collected"
rm "$rpath"/*.es_servers.list 2>/dev/null

# These are servers clusters, not ES clusters
for cluster in $clusternames ; do
  touch "$rpath/${cluster}.es_servers.list"
  [ -n "`eval echo -e \$${cluster}ips | tr ' ' '\n' | sort | $DIFF -q - "$rpath/${cluster}.es_servers.list"`" ] && eval echo -e \$${cluster}ips | tr ' ' '\n' | sort > "$rpath/${cluster}.es_servers.list"
done
$debug && log "server lists updated"

for node in `cat "$rpath"/*.es_servers.list 2>/dev/null` ; do
  if $HANDLE_NODES ; then
    allclusters="$allclusters $node|`$CURL -m 2 "http://$node/_cluster/state/_"|"$M_ROOT/lib/json2txt" | grep cluster_name | cut -sd'|' -f2 | tr -d '"'`"
  else
    allclusters="$allclusters $node|`$CURL -m 2 "http://$node/_cluster/state?filter_routing_table=true&filter_blocks=true&filter_nodes=true&filter_metadata=true"|"$M_ROOT/lib/json2txt" | grep cluster_name | cut -sd'|' -f2 | tr -d '"'`"
  fi
done

[ -z "$allclusters" ] && log "no ES clusters found, exiting" && unlock_exit 1

$debug && log "ES cluster(s) found: $allclusters"

date > "$rpath/elasticsearch.mon.report"
echo -e "-----------------------------\n" >> "$rpath/elasticsearch.mon.report"

### allclusters and escluster mean ES cluster, not servers cluster!
for escluster in `echo "$allclusters" | cut -d'|' -f2 | sort | uniq | grep -v ^$` ; do
  #rm -f "$rpath/${escluster}.nodes.list"
  #mv "$rpath/${escluster}.dat" "$rpath/${escluster}.dat.prev"
  clusterhost1=`echo $allclusters | sed 's| |\n|g' | grep "|${escluster}$" | sort | uniq | tail -1` ; clusterhost1=${clusterhost1%|*}
  clusterhost2=`echo $allclusters | sed 's| |\n|g' | grep "|${escluster}$" | sort | uniq | head -1` ; clusterhost2=${clusterhost2%|*}
  clusterport1=${clusterhost1#*:}
  clusterport2=${clusterhost2#*:}
  [[ "$clusterport1" == "$clusterport2" ]] || echo "Different port numbers for cluster ${escluster}: $clusterport1 $clusterport2  - please keep your environment sane!"
  [ -n "$clusterport1" ] && clusterport="$clusterport1" || clusterport="$clusterport2"
  $debug && log "ES cluster ${escluster}: 2 random hosts selected: $clusterhost1 and $clusterhost2"
  
  health=`($CURL -m 2 "http://$clusterhost1/_cluster/health" || $CURL -m 5 "http://$clusterhost2/_cluster/health") | "$M_ROOT"/lib/json2txt`
  mv "$rpath/${escluster}.dat" "$rpath/${escluster}.dat.prev"
  echo "$health" > "$rpath/${escluster}.dat"
  $debug && log "ES cluster ${escluster}: health data collected"
  
  IFS1=$IFS
  IFS='
'
  for LINE in `cat "$rpath/${escluster}.dat" 2>/dev/null | cut -d'/' -f2 | sed 's_|_=_g;s_^"__;s_"=_=_'` ; do eval $LINE ; done
  IFS=$IFS1
  
  $debug && log "ES cluster ${escluster}: health data parsed"
  
  number_of_nodes_was=`grep '"number_of_nodes"|' "$rpath/${escluster}.dat.prev" | cut -d'|' -f2`
  number_of_data_nodes_was=`grep '"number_of_data_nodes"|' "$rpath/${escluster}.dat.prev" | cut -d'|' -f2`
  active_primary_shards_was=`grep '"active_primary_shards"|' "$rpath/${escluster}.dat.prev" | cut -d'|' -f2`
  active_shards_was=`grep '"active_shards"|' "$rpath/${escluster}.dat.prev" | cut -d'|' -f2`

  echo -e "Cluster: $escluster\n-------------------\n" > "$rpath/${escluster}.report"
  
  if [ "_$status" == "_green" ] ; then
    warnind='<OK> '
  elif [ "_$status" == "_yellow" ] ; then
    warnind='<**> '
  else
    warnind='<***>'
  fi
  
  echo "$warnind Cluster status: $status" >> "$rpath/${escluster}.report"
  [ "_$timed_out" == "_false" ] && warnind='<OK> ' || warnind='<***>'
  echo "$warnind Timed out: $timed_out" >> "$rpath/${escluster}.report"
  [ "_$number_of_nodes" == "_$number_of_nodes_was" ] && warnind='<OK> ' || warnind=' <*> '
  echo "$warnind Number of nodes: $number_of_nodes" >> "$rpath/${escluster}.report"
  [ "_$number_of_data_nodes" == "_$number_of_data_nodes_was" ] && warnind='<OK> ' || warnind=' <*> '
  echo "$warnind Number of data nodes: $number_of_data_nodes" >> "$rpath/${escluster}.report"
  [ "_$active_primary_shards" == "_$active_primary_shards_was" ] && warnind='<OK> ' || warnind=' <*> '
  echo "$warnind Active primary shards: $active_primary_shards" >> "$rpath/${escluster}.report"
  [ "_$active_shards" == "_$active_shards_was" ] && warnind='<OK> ' || warnind=' <*> '
  echo "$warnind Active shards: $active_shards" >> "$rpath/${escluster}.report"
  [ "_$relocating_shards" == "_0" ] && warnind='<OK> ' || warnind=' <*> '
  echo "$warnind Relocating shards: $relocating_shards" >> "$rpath/${escluster}.report"
  [ "_$initializing_shards" == "_0" ] && warnind='<OK> ' || warnind=' <*> '
  echo "$warnind Initializing shards: $initializing_shards" >> "$rpath/${escluster}.report"
  [ "_$unassigned_shards" == "_0" ] && warnind='<OK> ' || warnind='<***>'
  echo "$warnind Unassigned shards: $unassigned_shards" >> "$rpath/${escluster}.report"
  $debug && log "ES cluster ${escluster}: health report generated"
  
  if [ "_$SQLITE3" == "_1" ] ; then
    $SQLITE "$rpath/elasticsearch.sql3" "INSERT INTO cluster (timeindex, day, name, status, timed_out, number_of_nodes, number_of_data_nodes, active_primary_shards, active_shards, relocating_shards, initializing_shards, unassigned_shards) values ($timeindexnow, '`date +"%Y%m%d"`', '$cluster_name', '$status', '$timed_out', $number_of_nodes, $number_of_data_nodes, $active_primary_shards, $active_shards, $relocating_shards, $initializing_shards, $unassigned_shards)"
    unset name status timed_out number_of_nodes number_of_data_nodes active_primary_shards active_shards relocating_shards initializing_shards unassigned_shards
  fi
  $debug && log "ES cluster ${escluster}: health data stored in database"
  if $HANDLE_NODES ; then
    nodes=`($CURL -m 3 "http://$clusterhost1/_cluster/state/nodes" || $CURL -m 6 "http://$clusterhost2/_cluster/state/nodes") | "$M_ROOT"/lib/json2txt`
  else
    nodes=`($CURL -m 3 "http://$clusterhost1/_cluster/state?filter_routing_table=true&filter_blocks=true&filter_metadata=true" || $CURL -m 6 "http://$clusterhost2/_cluster/state?filter_routing_table=true&filter_blocks=true&filter_metadata=true") | "$M_ROOT"/lib/json2txt`
  fi
  echo "$nodes" > "$rpath/data/${escluster}.nodes"
  $debug && log "ES cluster ${escluster}: nodes list compiled"
  # at last, the full list of nodes for ES cluster (might be scattered across
  # different servers clusters and clusters might not all be defined in .conf)
  
  ## This dumb test is needed to ensure that there is no ghost clusters that could form because of connectivity problems.
#  for clusterhost in "$clusterhost1" "$clusterhost2" ; do
#    for clusternode in `cat "$rpath/data/${escluster}.nodes" | grep ^1\/nodes\/ | cut -d'/' -f3 | sort | uniq` ; do
  
#    thisnodename=`$CURL -m 2 -s "http://${clusterhost}/_cluster/nodes" | "$M_ROOT/lib/json2txt" | grep "/nodes/$clusternode/name|" | cut -d'|' -f2`
#    [ -z "$thisnodename" ] && echo "<***> Node $clusternode not known to the node located on the host ${clusterhost}" >> "$rpath/elasticsearch.mon.report"
#    done
#  done
  
  for clusternode in `cat "$rpath/data/${escluster}.nodes" 2>/dev/null | grep ^0\/\"nodes\"\/ | cut -d'/' -f3 | sort | uniq` ; do
    clusternode=`echo $clusternode | sed 's|-|\\\-|g;s|"||g'`
    # This clusternode is an ID assigned by ES, like 2dsOVGfwR5GjTpyA-jbbGw
    ismaster=`grep ^0\/\"master_node\" "$rpath/data/${escluster}.nodes" | grep -c "$clusternode"`
    nodehost=`grep "\"$clusternode\"\/\"transport_address\"|" "$rpath/data/${escluster}.nodes"`
    nodehost=${nodehost#/transport_address|}
    nodehost=${nodehost%:*}
    nodehost=${nodehost##*/}
    rname=`ip_to_name "$nodehost" 2>/dev/null`
    clusternode=`echo $clusternode | sed 's|\\\||g'`
    $debug && log "ES cluster ${escluster}: getting details of the node $clusternode from host $rname (${nodehost})"
    
    if [ -n "$rname" ] ; then
      hostport="${rname}:${clusterport}"
    else
      hostport="${nodehost}:${clusterport}"
      rname="$nodehost"
    fi
    eval "${escluster}nodes+=( \"${hostport}\" )"
    echo -e "clusternode_id|$clusternode\nip|$nodehost\nmaster|$ismaster" > "$rpath/data/${escluster}.${rname}.dat.tmp"
    
    if $HANDLE_NODES ; then
      ($CURL -m 5 "http://$clusterhost1/_nodes/$clusternode/stats/indices,process,jvm,network,transport,http" || $CURL -m 5 "http://$clusterhost2/_nodes/$clusternode/stats/indices,process,jvm,network,transport,http") | "$M_ROOT"/lib/json2txt | cut -d'/' -f4- >> "$rpath/data/${escluster}.${rname}.dat.tmp"
    else
      ($CURL -m 5 "http://$clusterhost1/_cluster/nodes/$clusternode/stats?indices&process&jvm&network&transport&http" || $CURL -m 5 "http://$clusterhost2/_cluster/nodes/$clusternode/stats?indices&process&jvm&network&transport&http") | "$M_ROOT"/lib/json2txt | cut -d'/' -f4- >> "$rpath/data/${escluster}.${rname}.dat.tmp"
    fi

    mv "$rpath/data/${escluster}.${rname}.dat" "$rpath/data/${escluster}.${rname}.dat.prev"
    mv "$rpath/data/${escluster}.${rname}.dat.tmp" "$rpath/data/${escluster}.${rname}.dat"
    $debug && log "    JSON stats parsed and saved to file"
    
    if [ "_$SQLITE3" == "_1" ] ; then
      master=`grep ^master\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      ind_size=`grep ^\"indices\"\/\"store\"\/\"size_in_bytes\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      ind_docsnum=`grep ^\"indices\"\/\"docs\"\/\"count\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`

      open_file_descriptors=`grep ^\"process\"\/\"open_file_descriptors\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      proc_cpu_sys=$(expr \( `grep ^\"process\"\/\"cpu\"/\"sys_in_millis\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2` - `grep ^\"process\"\/\"cpu\"/\"sys_in_millis\"\| "$rpath/data/${escluster}.${rname}.dat.prev" | cut -d'|' -f2` \) / 1000 2>/dev/null) || proc_cpu_sys=0
      proc_cpu_user=$(expr \( `grep ^\"process\"\/\"cpu\"\/\"user_in_millis\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2` - `grep ^\"process\"\/\"cpu\"\/\"user_in_millis\"\| "$rpath/data/${escluster}.${rname}.dat.prev" | cut -d'|' -f2` \) / 1000 2>/dev/null) || proc_cpu_user=0
      proc_mem_res=`grep ^\"process\"\/\"mem\"\/\"resident_in_bytes\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      proc_mem_share=`grep ^\"process\"\/\"mem\"\/\"share_in_bytes\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      proc_mem_virt=`grep ^\"process\"\/\"mem\"\/\"total_virtual_in_bytes\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      jvm_uptime=$(expr `grep ^\"jvm\"\/\"uptime_in_millis\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2` / 1000 2>/dev/null) || jvm_uptime=0
      jvm_mem_heap_used=`grep ^\"jvm\"\/\"mem\"\/\"heap_used_in_bytes\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      jvm_mem_heap_committed=`grep ^\"jvm\"\/\"mem\"\/\"heap_committed_in_bytes\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      jvm_mem_nonheap_used=`grep ^\"jvm\"\/\"mem\"\/\"non_heap_used_in_bytes\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      jvm_mem_nonheap_committed=`grep ^\"jvm\"\/\"mem\"\/\"non_heap_committed_in_bytes\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      jvm_threads=`grep ^\"jvm\"\/\"threads\"\/\"count\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      network_active_opens=$(expr `grep ^\"network\"\/\"tcp\"\/\"active_opens\"\| $rpath/data/${escluster}.${rname}.dat | cut -d'|' -f2` - `grep ^\"network\"\/\"tcp\"\/\"active_opens\"\| "$rpath/data/${escluster}.${rname}.dat.prev" | cut -d'|' -f2` 2>/dev/null) || network_active_opens=0
      network_passive_opens=$(expr `grep ^\"network\"\/\"tcp\"\/\"passive_opens\"\| $rpath/data/${escluster}.${rname}.dat | cut -d'|' -f2` - `grep ^\"network\"\/\"tcp\"\/\"passive_opens\"\| "$rpath/data/${escluster}.${rname}.dat.prev" | cut -d'|' -f2` 2>/dev/null) || network_passive_opens=0
      network_curr_estab=`grep ^\"network\"\/\"tcp\"\/\"curr_estab\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      transport_server_open=`grep ^\"transport\"\/\"server_open\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      http_server_open=`grep ^\"http\"\/\"current_open\"\| "$rpath/data/${escluster}.${rname}.dat" | cut -d'|' -f2`
      $debug && log "    stats put to variables"
      $SQLITE "$rpath/elasticsearch.sql3" "INSERT INTO nodes (timeindex, day, hostport, master, ind_size, ind_docsnum, open_file_descriptors, proc_cpu_sys, proc_cpu_user, proc_mem_res, proc_mem_share, proc_mem_virt, jvm_uptime, jvm_mem_heap_used, jvm_mem_heap_committed, jvm_mem_nonheap_used, jvm_mem_nonheap_committed, jvm_threads, network_active_opens, network_passive_opens, network_curr_estab, transport_server_open, http_server_open) values ($timeindexnow, '`date +"%Y%m%d"`', '${hostport}', '$master', '$ind_size', '$ind_docsnum', '$open_file_descriptors', '${proc_cpu_sys-0}', '${proc_cpu_user-0}', '${proc_mem_res-0}', '${proc_mem_share-0}', '${proc_mem_virt-0}', '${jvm_uptime-0}', '${jvm_mem_heap_used-0}', '${jvm_mem_heap_committed-0}', '${jvm_mem_nonheap_used-0}', '${jvm_mem_nonheap_committed-0}', '${jvm_threads-0}', '${network_active_opens-0}', '${network_passive_opens-0}', '${network_curr_estab-0}', '${transport_server_open-0}', '${http_server_open-0}')"
      unset hostport master ind_size ind_docsnum open_file_descriptors proc_cpu_sys proc_cpu_user proc_mem_res proc_mem_share proc_mem_virt jvm_uptime jvm_mem_heap_used jvm_mem_heap_committed jvm_mem_nonheap_used jvm_mem_nonheap_committed jvm_threads network_active_opens network_passive_opens network_curr_estab transport_server_open http_server_open
      $debug && log "    stats stored in database, variables unset"
    fi
    
  done
  
  eval echo -e \${${escluster}nodes[*]} | tr ' ' '\n' | sort > "$rpath"/${escluster}.nodes.list
  
  if $HANDLE_NODES ; then
    routes=`($CURL -m 5 "http://$clusterhost1/_cluster/state/routing_table" || $CURL -m 10 "http://$clusterhost2/_cluster/state/routing_table") | "$M_ROOT"/lib/json2txt`
  else
    routes=`($CURL -m 5 "http://$clusterhost1/_cluster/state?filter_blocks=true&filter_nodes=true&filter_metadata=true" || $CURL -m 10 "http://$clusterhost2/_cluster/state?filter_blocks=true&filter_nodes=true&filter_metadata=true") | "$M_ROOT"/lib/json2txt`
  fi
  echo "$routes" > "$rpath/data/${escluster}.routing"
  $debug && log "ES cluster ${escluster}: routing data collected"
  
  declare -i m
  for shard in `cat "$rpath/data/${escluster}.routing" 2>/dev/null | grep '^0/"routing_table"/"indices"/"streams"/"shards"/' | cut -d'/' -f6 | grep ^[0-9] | sort | uniq` ; do
    rm -f "$rpath/data/${escluster}.${shard}.routing"
    m=0 ; cat "$rpath/data/${escluster}.routing" 2>/dev/null | grep "^0/\"routing_table\"/\"indices\"/\"streams\"/\"shards\"/\"$shard\"/" | sed 's|^0/"routing_table"/"indices"/"streams"/"shards"/||g' | grep -v "^\"$shard\"/\"shard\" " | while read routline ; do routlines=( ${routlines[*]} "${routline%%|*}" ) ; [[ "${routline%%|*}" == "${routlines[0]}" ]] && m+=1; echo "$m/${routline#*/}" >> "$rpath/data/${escluster}.${shard}.routing" ; done
    unset routlines
  done
  $debug && log "ES cluster ${escluster}: routing data processed"
  
  cat "$rpath/${escluster}.report" >> "$rpath/elasticsearch.mon.report"
done
$debug && log "done with clusters"

# lazily removing stale data (terminated clusters etc)
find "$rpath/data/" -type f -mmin +60 -exec rm {} \;
find "$rpath/" -name "*.dat" -o -name "*.dat.prev" -o -name "*.nodes.list" -mmin +60 -exec rm {} \;
# keeping report for 1 day, it may contain something useful
# ( the last known state of a disappeared cluster :) )
find "$rpath/" -name "*.report" -mtime +1 -exec rm {} \;
$debug && log "finish"

release_lock

