#!/bin/bash

[[ $0 =~ ^\/ ]] && rroot='/'
for step in `echo ${0} | tr '/' ' '` ; do
  rlink=`readlink "${rroot}${rpath}${step}"`
  if [ -n "$rlink" ] ; then
    [[ $rlink =~ ^\/ ]] && rpath="${rlink}/" || rpath="${rpath}${rlink}/"
  else
    rpath="${rpath}${step}/"
  fi
done
rpath=${rpath%/}
rcommand=${rpath##*/}
rpath="${rroot}${rpath%/*}"
echo "Running ${rpath}/${rcommand}" >> "${rpath}/../../sa.log"
#*/
DIFF=`which diff 2>/dev/null`
[ -z "$DIFF" ] && echo "Diff utility not found, exiting..  " && exit 1
CURL=`which curl 2>/dev/null`
[ -z "$CURL" ] && echo "Curl not found, exiting..  " && exit 1
CURL="$CURL -s"
source "${rpath}/${rcommand%.mon}.conf"
source "${rpath}/../../conf/mon.conf"
SQLITE=`which sqlite3 2>/dev/null`

TMPDIR="${TMPDIR}/elasticsearch"
install -d "${TMPDIR}"
timeindexnow=`date +"%s"`

function ip_to_name() {
  rname1=`grep "^${1%:*}[[:space:]]" /etc/hosts | awk '{print $2}'`
  [ -n "$rname1" ] && rname2=`grep "^${1%:*}[[:space:]]" /etc/hosts | awk '{print $3}'` || rname=${1%:*}
  [ -n "$rname2" ] && [ ${#rname2} -lt ${#rname1} ] && rname=$rname2 || rname=$rname1
  [ -n "$rname" ] || rname=${1%:*}
}

function print_servers() {
  for host in $@ ; do
    echo "$host"
  done
}

function collect_hosts() {
  for name in $@ ; do
    port=${name#*:}
    [ "X$port" == "X$name" ] && unset port
    ip_to_name $name
    [ -n "$port" ] || port=$defaultport
    configips="$configips ${rname}:$port"
  done
}

if [ -n "$ES_SERVERS" ] ; then
  defaultport=9200
  ES_SERVERS=`echo $ES_SERVERS | sed 's|,| |g'`
  for name in $ES_SERVERS ; do
    if [ `grep -c ^${name}\| "${rpath}/../../conf/clusters.conf"` -eq 0 ] ; then
      noncluster=1
    else
      cluster=1
    fi
    # In case some server has the same name as cluster
    if [ `grep -c "|${name}|${name}" "${rpath}/../../servers.list"` -gt 0 ] ; then
      unset cluster
    fi
  done
  
  [ "X$cluster" == "X1" ] && [ "X$noncluster" == "X1" ] && echo "Wrong cluster name in ES_SERVERS or both cluster and server names are present which is not supported" && exit 1
  if [ "X$noncluster" == "X1" ] ; then
  # ES_SERVERS contains hosts
    for server in $ES_SERVERS ; do
      port=":${server#*:}"
      host=${server%:*}
      [ "X$port" == "X:$host" ] && unset port
      clustername=`cat "${rpath}/../../servers.list" | grep -E "\|${host}\||^${host}\|" | cut -d'|' -f5`
      [ "X$clustername" == "X$clusternameprev" ] && continue
      clusterips=`"${rpath}/../../cloud/ec2/get_ips" --cluster="${clustername}"|sed "s|$|$port|g"`
      clusternameprev=$clustername
      clusternames="$clusternames $clustername"
      collect_hosts $clusterips
      print_servers $configips > "${TMPDIR}/${clustername}.es_servers.list" | tee -a ${rpath}/../../logs/elasticsearch.log
    done
  else
  # ES_SERVERS contains clusters
    for name in $ES_SERVERS ; do
      clustername=${name%:*}
      port=":${name#*:}"
      [ "X$port" == "X:$clustername" ] && unset port
      clusterips=`"${rpath}/../../cloud/ec2/get_ips" --cluster="${clustername}"|sed "s|$|${port}|g"`
      collect_hosts $clusterips
      print_servers $configips > "${TMPDIR}/${clustername}.es_servers.list" | tee -a ${rpath}/../../logs/elasticsearch.log
    done
    clusternames="$clusternames $clustername"
  fi
else
  echo "ES_SERVERS variable is not defined, check ${rcommand}.conf" >> ${rpath}/../../logs/elasticsearch.log
fi

for cluster in $clusternames ; do
  touch "${rpath}/${cluster}.es_servers.list"
  [ -f "${TMPDIR}/${cluster}.es_servers.list" ] && [ -f "${rpath}/${cluster}.es_servers.list" ] && [ -n "`$DIFF -q "${TMPDIR}/${cluster}.es_servers.list" "${rpath}/${cluster}.es_servers.list"`" ] && mv "${TMPDIR}/${cluster}.es_servers.list" "${rpath}/${cluster}.es_servers.list"
  
  #node=`tail -1 "${rpath}/${cluster}.es_servers.list"`
  #$CURL "http://${node}/_cluster/nodes" | lib/json2txt > "${rpath}/data/${cluster}.nodes"
  #$CURL "http://${node}/_cluster/nodes/stats" | ${rpath}/../../lib/json2txt > "${rpath}/data/${cluster}.nodes_stats"
  #$CURL "http://${node}/_cluster/state?filter_routing_table=true&filter_metadata=true&filter_blocks=true&filter_indices=true" | ${rpath}/../../lib/json2txt > "${rpath}/data/${cluster}.nodes"
  
done

for node in `cat "${rpath}"/*.es_servers.list` ; do
  allclusters="$allclusters `$CURL "http://${node}/_cluster/state?filter_routing_table=true&filter_blocks=true&filter_nodes=true&filter_metadata=true"|${rpath}/../../lib/json2txt | cut -d'/' -f2 | grep cluster_name | awk "{print \\"${node}|\\" \\$2}"`"
done

for cluster in `echo $allclusters | sed 's| |\n|g' | cut -d'|' -f2 | sort | uniq | grep -v ^$` ; do
  clusterhost1=`echo $allclusters | sed 's| |\n|g' | grep "|${cluster}$" | tail -1` ; clusterhost1=${clusterhost1%|*}
  clusterhost2=`echo $allclusters | sed 's| |\n|g' | grep "|${cluster}$" | head -1` ; clusterhost2=${clusterhost2%|*}
  ($CURL "http://${clusterhost1}/_cluster/state?filter_routing_table=true&filter_blocks=true&filter_metadata=true" || $CURL "http://${clusterhost2}/_cluster/state?filter_routing_table=true&filter_blocks=true&filter_metadata=true") | ${rpath}/../../lib/json2txt > "${rpath}/data/${cluster}.nodes"
  for clusternode in `cat "${rpath}/data/${cluster}.nodes" | grep ^1\/nodes\/ | cut -d'/' -f3 | sort | uniq` ; do
    # This clusternode is an ID assigned by ES, like 2dsOVGfwR5GjTpyA-jbbGw
    ismaster=`grep ^1\/master_node "${rpath}/data/${cluster}.nodes" | grep -c "$clusternode"`
    nodehost=`grep "${clusternode}\/transport_address " "${rpath}/data/${cluster}.nodes"`
    nodehost=${nodehost#/transport_address }
    nodehost=${nodehost%:*}
    nodehost=${nodehost##*/}
    ip_to_name "$nodehost"
    mv "${rpath}/data/${cluster}.${rname}.dat" "${rpath}/data/${cluster}.${rname}.dat.prev"
    echo -e "clusternode_id|${clusternode}\nip|${nodehost}\nmaster|${ismaster}" > "${rpath}/data/${cluster}.${rname}.dat"
    ($CURL "http://${clusterhost1}/_cluster/nodes/${clusternode}/stats" || $CURL "http://${clusterhost2}/_cluster/nodes/${clusternode}/stats") | ${rpath}/../../lib/json2txt | awk -F"${clusternode}/" '{print $2}' | sed 's_^\([^[:space:]]*\) _\1|_g' >> "${rpath}/data/${cluster}.${rname}.dat"
    if [ "X$SQLITE3" == "X1" ] ; then
      hostport=`grep ^$nodehost\: "${rpath}"/${cluster}.es_servers.list | tail -1`
      [ -n "$hostport" ] || hostport=`grep ^$rname\: "${rpath}"/${cluster}.es_servers.list | tail -1`
      master=`grep ^master\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      ind_size=`grep ^indices\/size_in_bytes\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      ind_docsnum=`grep ^indices\/docs\/num_docs\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      ind_cache_field_evictions=`grep ^indices\/cache\/field_evictions\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      ind_cache_field_size=`grep ^indices\/cache\/field_size_in_bytes\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      ind_cache_filter_count=`grep ^indices\/cache\/filter_count\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      ind_cache_filter_evictions=`grep ^indices\/cache\/filter_evictions\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      ind_cache_filter_size=`grep ^indices\/cache\/filter_size_in_bytes\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      ind_merges=$(expr `grep ^indices\/merges\/total\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2` - `grep ^indices\/merges\/total\| ${rpath}/data/${cluster}.${rname}.dat.prev | cut -d'|' -f2`)
      ind_merges_time=$(expr \( `grep ^indices\/merges\/total_time_in_millis\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2` - `grep ^indices\/merges\/total_time_in_millis\| ${rpath}/data/${cluster}.${rname}.dat.prev | cut -d'|' -f2` \) / 1000 )
      open_file_descriptors=`grep ^process\/open_file_descriptors\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      proc_cpu_sys=$(expr \( `grep ^process\/cpu/sys_in_millis\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2` - `grep ^process\/cpu/sys_in_millis\| ${rpath}/data/${cluster}.${rname}.dat.prev | cut -d'|' -f2` \) / 1000)
      proc_cpu_user=$(expr \( `grep ^process\/cpu\/user_in_millis\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2` - `grep ^process\/cpu\/user_in_millis\| ${rpath}/data/${cluster}.${rname}.dat.prev | cut -d'|' -f2` \) / 1000)
      proc_mem_res=`grep ^process\/mem\/resident_in_bytes\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      proc_mem_share=`grep ^process\/mem\/share_in_bytes\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      proc_mem_virt=`grep ^process\/mem\/total_virtual_in_bytes\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      jvm_uptime=$(expr `grep ^jvm\/uptime_in_millis\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2` / 1000)
      jvm_mem_heap_used=`grep ^jvm\/mem\/heap_used_in_bytes\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      jvm_mem_heap_committed=`grep ^jvm\/mem\/heap_committed_in_bytes\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      jvm_mem_nonheap_used=`grep ^jvm\/mem\/non_heap_used_in_bytes\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      jvm_mem_nonheap_committed=`grep ^jvm\/mem\/non_heap_committed_in_bytes\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      jvm_threads=`grep ^jvm\/threads\/count\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      network_active_opens=$(expr `grep ^network\/tcp\/active_opens\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2` - `grep ^network\/tcp\/active_opens\| ${rpath}/data/${cluster}.${rname}.dat.prev | cut -d'|' -f2`)
      network_passive_opens=$(expr `grep ^network\/tcp\/passive_opens\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2` - `grep ^network\/tcp\/passive_opens\| ${rpath}/data/${cluster}.${rname}.dat.prev | cut -d'|' -f2`)
      network_curr_estab=`grep ^network\/tcp\/curr_estab\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      transport_server_open=`grep ^transport\/server_open\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      http_server_open=`grep ^http\/server_open\| ${rpath}/data/${cluster}.${rname}.dat | cut -d'|' -f2`
      $SQLITE "${rpath}/elasticsearch.sql3" "INSERT INTO nodes (timeindex, day, hostport, master, ind_size, ind_docsnum, ind_cache_field_evictions, ind_cache_field_size, ind_cache_filter_count, ind_cache_filter_evictions, ind_cache_filter_size, ind_merges, ind_merges_time, open_file_descriptors, proc_cpu_sys, proc_cpu_user, proc_mem_res, proc_mem_share, proc_mem_virt, jvm_uptime, jvm_mem_heap_used, jvm_mem_heap_committed, jvm_mem_nonheap_used, jvm_mem_nonheap_committed, jvm_threads, network_active_opens, network_passive_opens, network_curr_estab, transport_server_open, http_server_open) values ($timeindexnow, '`date +"%Y%m%d"`', '${hostport}', $master, $ind_size, $ind_docsnum, $ind_cache_field_evictions, $ind_cache_field_size, $ind_cache_filter_count, $ind_cache_filter_evictions, $ind_cache_filter_size, $ind_merges, $ind_merges_time, $open_file_descriptors, $proc_cpu_sys, $proc_cpu_user, $proc_mem_res, $proc_mem_share, $proc_mem_virt, $jvm_uptime, $jvm_mem_heap_used, $jvm_mem_heap_committed, $jvm_mem_nonheap_used, $jvm_mem_nonheap_committed, $jvm_threads, $network_active_opens, $network_passive_opens, $network_curr_estab, $transport_server_open, $http_server_open)"
    unset hostport master ind_size ind_docsnum ind_cache_field_evictions ind_cache_field_size ind_cache_filter_count ind_cache_filter_evictions ind_cache_filter_size ind_merges ind_merges_time open_file_descriptors proc_cpu_sys proc_cpu_user proc_mem_res proc_mem_share proc_mem_virt jvm_uptime jvm_mem_heap_used jvm_mem_heap_committed jvm_mem_nonheap_used jvm_mem_nonheap_committed jvm_threads network_active_opens network_passive_opens network_curr_estab transport_server_open http_server_open
    fi
  done
  ($CURL "http://${clusterhost1}/_cluster/state?filter_blocks=true&filter_nodes=true&filter_metadata=true" || $CURL "http://${clusterhost2}/_cluster/state?filter_blocks=true&filter_nodes=true&filter_metadata=true") | ${rpath}/../../lib/json2txt > "${rpath}/data/${cluster}.routing"
  for shard in `cat "${rpath}/data/${cluster}.routing" | grep '1/routing_table/indices/streams/shards/' | cut -d'/' -f6 | grep ^[0-9] | sort | uniq` ; do
    rm -f "${rpath}/data/${cluster}.${shard}.routing"
    declare -i m ; declare -i n ; m=0 ; n=0 ; cat "${rpath}/data/${cluster}.routing" | grep "1/routing_table/indices/streams/shards/${shard}/" | sed 's|^1/routing_table/indices/streams/shards/||g' | grep -v "^${shard}/shard " | while read routline ; do routlines=( ${routlines[*]} "${routline%% *}" ) ; for ((i=0; i<$n; i++)) ; do [[ "${routlines[$i]}" == "${routlines[$n]}" ]] && m+=1; done ; n+=1 ; echo "${m}/${routline}" >> "${rpath}/data/${cluster}.${shard}.routing" ; done
    
  done
done

